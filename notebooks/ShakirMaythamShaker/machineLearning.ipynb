{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "props_pageProps_address_municipality_name\n",
      "Brøndby    80\n",
      "Name: count, dtype: int64\n",
      "(80, 22)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 500)  # Replace 100 with the desired number\n",
    "pd.set_option('display.max_columns', 500)  # Replace 100 with the desired number\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('cleanedNewTest.csv')\n",
    "\n",
    "\n",
    "# Test model performance when filtering within5 years\n",
    "data = data[data['years_from_today'] < 5]\n",
    "\n",
    "# Penalitize old transactions as a correction for inflation and other economic factors.\n",
    "data['years_from_today_weighted'] = data['years_from_today'] ** 2\n",
    "\n",
    "# Test model performance on specific municipalities\n",
    "municipalities = ['Brøndby']\n",
    "data = data[data['props_pageProps_address_municipality_name'].isin(municipalities)]\n",
    "\n",
    "print(data['props_pageProps_address_municipality_name'].value_counts())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakirmshaker/Library/Mobile Documents/com~apple~CloudDocs/Skole/DTU/ComputationalTools/Project/venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13133.199401142369, 114.60017190712398)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the target variable (let's choose 'sqm_price' for this example)\n",
    "target = 'sqm_price'\n",
    "\n",
    "# Preparing the data for the model\n",
    "X = data.drop([target, 'lastPrice', 'props_pageProps_address_events_0_at', 'props_pageProps_address_events_0_label',\n",
    "               'props_pageProps_dataLayer_virtualPagePath', 'props_pageProps_dataLayer_detailMetaData', 'years_from_today',\n",
    "               'props_pageProps_address_coordinates_lat', 'props_pageProps_address_coordinates_lon'], axis=1)\n",
    "\n",
    "y = data[target]\n",
    "\n",
    "# Encoding categorical variables\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Standardizing numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Combining encoded categorical and scaled numerical features\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=numerical_cols)\n",
    "X_combined = pd.concat([X_scaled_df, X_encoded_df], axis=1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training a RandomForestRegressor model\n",
    "model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "# Outputting the model's performance\n",
    "mse, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning model performs very good on for example Brøndby with almost no outliers, and very bad on for example Frederiksberg with many diverse transactions. This could indicate that clustering within each municiplaity could be a good way to handle and label the outliers instead of removing them and thereefter use their labels as inputs in a machine learning model. Also, an approach could be to train a specific model for each municipality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
